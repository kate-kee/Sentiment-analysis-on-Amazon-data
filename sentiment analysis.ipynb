{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0b9e63",
   "metadata": {},
   "source": [
    "<h1>Sentiment analysis on amazon product reviews</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e05867c",
   "metadata": {},
   "source": [
    "<h6>In this notebook I make a real world python machine learning project using the sci-kit learn library. In it I build a model that automatically classifies text as either having a positive or negative sentiment. I do this by using amazon reviews as the training data and using multiple machine learning algorithms for classifying the data. Upon finding the best model, I store it in a pkl file so that we don't need to re-train the data</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d180e356",
   "metadata": {},
   "source": [
    "<p>For our analysis, I have taken a dataset of 10000 user reviews and trimmed it to keep only two columns which are review text and rating of the product.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006d732e",
   "metadata": {},
   "source": [
    "<p>Creating an enumeration class that stores types of sentiments. For our analysis we take 3 types of sentiments</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ba55247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class Sentiment:\n",
    "    Negative=\"Negative\"\n",
    "    Neutral=\"Neutral\"\n",
    "    Positive=\"Positive\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6808ed",
   "metadata": {},
   "source": [
    "<p>Since the values of ratings are from 1-5, I converted them in 3 categorical values namely positive, negative and neutral usign the method get_sentiment of the class below.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a85402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review:\n",
    "    def __init__(self,text,score):\n",
    "        self.text=text\n",
    "        self.score=score\n",
    "        self.sentiment=self.get_sentiment()\n",
    "    def get_sentiment(self):\n",
    "        if self.score<=2:\n",
    "            return Sentiment.Negative\n",
    "        elif self.score==3:\n",
    "            return Sentiment.Neutral\n",
    "        else:\n",
    "            return Sentiment.Positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293b8a9",
   "metadata": {},
   "source": [
    "<h5>Trainig data is heavily biased towards positive data since 85% reviews are positive and less than 15% or so are negative \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619f53b",
   "metadata": {},
   "source": [
    "<p>Creating a container class which separates text, sentiments and the reviews</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98fce454",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewContainer:\n",
    "    def __init__(self,reviews):\n",
    "        self.reviews=reviews\n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.Negative, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.Positive, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848a7243",
   "metadata": {},
   "source": [
    "<p>Loading the dataset, loading the data from file and storing it in a list 'reviews'</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f779a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_name='books_small_10000.json'\n",
    "reviews=[]\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review=json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad78aa",
   "metadata": {},
   "source": [
    "<p>Creating sets for training and test data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5fc5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "training,test=train_test_split(reviews,test_size=0.33,random_state=42)\n",
    "\n",
    "train_container = ReviewContainer(training)\n",
    "\n",
    "test_container = ReviewContainer(test)\n",
    "train_container.evenly_distribute()\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_container.evenly_distribute()\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb0c4f",
   "metadata": {},
   "source": [
    "<p>Tokenizing words with sklearn</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfc624a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'computeIFD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-455d538daa37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_x_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_x_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcomputeIFD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'computeIFD' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "computeIFD(train_x_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sum_words = train_x_vectors.sum(axis=0) \n",
    "# words_freq = [(word, sum_words[0, idx]) for word, idx in     vectorizer.vocabulary_.items()]\n",
    "# words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "# for i in range(0,len(words_freq)):\n",
    "#     print(words_freq[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c088e66",
   "metadata": {},
   "source": [
    "## Classification of data with multiple algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844a2528",
   "metadata": {},
   "source": [
    "#### SVM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "count=0\n",
    "for i in range(0,len(test_x)):\n",
    "    if(clf_svm.predict(test_x_vectors[i])==test_y[i]):\n",
    "        count+=1;\n",
    "print(f'Correctly predicted {count} times.')\n",
    "print(f'Accurary is {count*100//len(test_x)} %')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3171bb8b",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e671526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec=DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors,train_y)\n",
    "count=0\n",
    "for i in range(0,len(test_x)):\n",
    "    if(clf_dec.predict(test_x_vectors[i])==test_y[i]):\n",
    "        count+=1\n",
    "    \n",
    "print(f'Correctly predicted {count} times.')\n",
    "print(f'Accurary is {count*100//len(test_x)} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a3d43",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3ba88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "count=0\n",
    "for i in range(0,len(test_x)):\n",
    "    if(clf_log.predict(test_x_vectors[i])==test_y[i]):\n",
    "        count+=1\n",
    "    \n",
    "print(f'Correctly predicted {count} times.')\n",
    "print(f'Accurary is {count*100//len(test_x)} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d602d75",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b150f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mean accuracy\n",
    "print(clf_svm.score(test_x_vectors,test_y))\n",
    "print(clf_dec.score(test_x_vectors,test_y))\n",
    "print(clf_log.score(test_x_vectors,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4256dfb5",
   "metadata": {},
   "source": [
    "<p> For now, let's skip neutral reviews as they are average</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf2a7e7",
   "metadata": {},
   "source": [
    "###### Finding the F1 score for positive and negative reviews using each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d516ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_y,clf_svm.predict(test_x_vectors),average=None,labels=[Sentiment.Positive,Sentiment.Negative])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1_score(test_y,clf_dec.predict(test_x_vectors),average=None,labels=[Sentiment.Positive,Sentiment.Neutral,Sentiment.Negative])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9052c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1_score(test_y,clf_log.predict(test_x_vectors),average=None,labels=[Sentiment.Positive,Sentiment.Neutral,Sentiment.Negative])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd9b27",
   "metadata": {},
   "source": [
    "###### <p>Since the F1 for SVM is highest,let's check if linear/rbf svm is better</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters={'kernel':('linear','rbf'),'C':(1,4,8,16,32)}\n",
    "svc=svm.SVC()\n",
    "clf=GridSearchCV(svc,parameters,cv=5)\n",
    "clf.fit(train_x_vectors,train_y)\n",
    "print(clf.score(test_x_vectors,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08181b2a",
   "metadata": {},
   "source": [
    "classification using rbf svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d7acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import svm\n",
    "\n",
    "clf_svmr = svm.SVC(kernel='rbf')\n",
    "\n",
    "clf_svmr.fit(train_x_vectors, train_y)\n",
    "count=0\n",
    "#check accuracy on the test data \n",
    "for i in range(0,len(test_x)):\n",
    "    #print(f'Predicted as {clf_svm.predict(test_x_vectors[i])} and actual value is {test_y[i]}')\n",
    "    if(clf_svmr.predict(test_x_vectors[i])==test_y[i]):\n",
    "        count+=1;\n",
    "print(f'Correctly predicted {count} times.')\n",
    "print(f'Accurary is {count*100//len(test_x)} %')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238dc502",
   "metadata": {},
   "source": [
    "increase in accuracy by 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cdbe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(clf_svmr.score(test_x_vectors,test_y))\n",
    "f1_score(test_y,clf_svmr.predict(test_x_vectors),average=None,labels=[Sentiment.Positive,Sentiment.Negative])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834216c0",
   "metadata": {},
   "source": [
    "###### The RBF_SVM model is giving the highest accurary so we are saving model using pickle so that we dont need to train it againabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd94ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('sentiment_classifier.pkl','wb') as f:\n",
    "    pickle.dump(clf_svmr,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37a51f",
   "metadata": {},
   "source": [
    "###### loading the saved and trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment_classifier.pkl','rb') as f:\n",
    "    loaded_clf=pickle.load(f)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccdaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it's working\n",
    "loaded_clf.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de4832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
